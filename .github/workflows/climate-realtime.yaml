name: Climate Realtime

on:
  push:
    branches:
      - main
  schedule:
  - cron: "0 * * * *"  # Run every hour only on the main branch

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Jupyter, Nbconvert, and Required Libraries
        run: |
          python -m pip install --upgrade pip 
          pip install .

      - name: Restore Cached Climate Data
        uses: actions/cache@v3
        with:
          path: data
          key: climate-data-${{ github.run_id }}
          restore-keys: |
            climate-data-

      - name: Configure AWS Credentials
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          set -x
          /usr/local/bin/aws  --version
          /usr/local/bin/aws  configure set aws_access_key_id $AWS_ACCESS_KEY_ID
          /usr/local/bin/aws  configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
          /usr/local/bin/aws  configure set default.region us-west-2

          mkdir -p data/climate
          # Get today's, yesterday's, and tomorrow's dates in the format YYYY-MM-DD
          TODAY=$(date '+%Y-%m-%d')
          YESTERDAY=$(date -d 'yesterday' '+%Y-%m-%d')
          LAST_TWO_DAYS=$(date -d '2 days ago' '+%Y-%m-%d')
          TOMORROW=$(date -d 'tomorrow' '+%Y-%m-%d')

          # Sync only the required folders from S3
          for DATE in "$LAST_TWO_DAYS" "$YESTERDAY" "$TODAY" "$TOMORROW"; do
            aws s3 sync "s3://microgreen-dev-esp32/dev/climate/ESP32-C3-84:FC:E6:01:09:B0/$DATE/" "data/climate/$DATE" --exact-timestamps --size-only
          done


          mkdir -p data/dehumidifier
          # Get today's, yesterday's, and tomorrow's dates in the format YYYY-MM-DD
          TODAY=$(date '+%Y-%m-%d')
          YESTERDAY=$(date -d 'yesterday' '+%Y-%m-%d')
          LAST_TWO_DAYS=$(date -d '2 days ago' '+%Y-%m-%d')
          TOMORROW=$(date -d 'tomorrow' '+%Y-%m-%d')

          # Sync only the required folders from S3
          for DATE in "$LAST_TWO_DAYS" "$YESTERDAY" "$TODAY" "$TOMORROW"; do
            aws s3 sync "s3://microgreen-dev-esp32/dev/climate/ESP32-C3-84:FC:E6:01:1D:CC/$DATE/" "data/dehumidifier/$DATE" --exact-timestamps --size-only
          done

      - name: Run
        env:
          CONFLUENCE_URL: ${{ vars.CONFLUENCE_URL }}
          CONFLUENCE_SPACE_KEY: ${{ vars.CONFLUENCE_SPACE_KEY }}
          CONFLUENCE_USERNAME: ${{ vars.CONFLUENCE_USERNAME }}
          CONFLUENCE_API_TOKEN: ${{ secrets.CONFLUENCE_API_TOKEN }}
        run: |
          cd data/climate
          climate-realtime
          mv *.svg ../../publication/source/climate
          
          climate-archive
          mv *.svg ../../publication/source/climate/archive
          
          cd ../dehumidifer
          climate-realtime
          mv *.svg ../../publication/source/dehumidifer 

          climate-archive
          mv *.svg ../../publication/source/dehumidifier/archive

          cd ../../publication
          make confluence | true

      - name: Cache Climate Data
        uses: actions/cache@v3
        with:
          path: data
          key: climate-data-${{ github.run_id }}
          restore-keys: |
            climate-data-